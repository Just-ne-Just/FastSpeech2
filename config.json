{
  "name": "one_batch_test",
  "n_gpu": 1,
  "preprocessing": {
    "sr": 22050,
    "spectrogram": {
      "type": "MelSpectrogram",
      "args": {
      }
    },
    "log_spec": true
  },
  "augmentations": {
    "wave": [
    ],
    "spectrogram": [
    ]
  },
  "arch": {
    "type": "FastSpeech2",
    "args": {
      "max_seq_len": 3000, 
      "encoder_n_layer": 4, 
      "vocab_size": 300, 
      "encoder_dim": 256, 
      "encoder_head": 2, 
      "pad": 0, 
      "encoder_conv1d_filter_size": 1024,
      "fft_conv1d_kernel": [9, 1],
      "fft_conv1d_padding": [4, 0],
      "decoder_n_layer": 4,
      "decoder_dim": 256,
      "decoder_head": 2,
      "decoder_conv1d_filter_size": 1024,
      "duration_predictor_filter_size": 256,
      "duration_predictor_kernel_size": 3,
      "pitch_predictor_filter_size": 256,
      "pitch_predictor_kernel_size": 3,
      "energy_predictor_filter_size": 256,
      "energy_predictor_kernel_size": 3,
      "num_mels": 80,
      "num_bins": 256,
      "dropout": 0.1
    }
  },
  "data": {
    "train": {
      "batch_size": 20,
      "batch_expand_size": 48,
      "num_workers": 0,
      "datasets": [
          {
              "type": "LJspeechDataset",
              "args": {
                  "data_path": "/kaggle/input/tts-dataset/alignment/alignment/train.txt",
                  "wav_path": "/kaggle/input/tts-dataset/LJSpeech-1.1",
                  "mel_ground_truth": "/kaggle/input/tts-dataset/mel/mels",
                  "alignment_path": "/kaggle/input/tts-dataset/alignments/alignments",
                  "text_cleaners": ["english_cleaners"],
                  "pitch_path": "/kaggle/input/tts-dataset/pitch/pitch",
                  "energy_path": "/kaggle/input/tts-dataset/energy/energy",
                  "batch_expand_size": 32
              }
          }
      ]
    }
  },
  "optimizer": {
    "type": "AdamW",
    "args": {
      "lr": 3e-4,
      "weight_decay": 1e-5
    }
  },
  "loss": {
    "type": "TTSLoss",
    "args": {
    }
  },
  "metrics": [
  ],
  "lr_scheduler": {
    "type": "OneCycleLR",
    "args": {
      "steps_per_epoch": 3000,
      "epochs": 30,
      "anneal_strategy": "cos",
      "max_lr": 3e-4,
      "pct_start": 0.2
    }
  },
  "trainer": {
    "epochs": 60,
    "save_dir": "saved/",
    "save_period": 5,
    "verbosity": 2,
    "monitor": "min train_loss",
    "early_stop": 100,
    "visualize": "wandb",
    "wandb_project": "tts_project",
    "len_epoch": 3000,
    "grad_norm_clip": 10
  }
}